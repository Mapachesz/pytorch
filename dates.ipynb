{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This project use python 3.12.2 enviroment\n",
    "#The enviroment helpful to analytics with libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3501"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the dates \n",
    "data = pd.read_csv(\"speed_data.csv\")\n",
    "data.head()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Separate target variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dates_y \u001b[38;5;241m=\u001b[39m \u001b[43mdates\u001b[49m[dates\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m5\u001b[39m]]\n\u001b[0;32m      3\u001b[0m dates_y\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#All other dates\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dates' is not defined"
     ]
    }
   ],
   "source": [
    "#Separate target variable\n",
    "data_y = data[data.columns[5]]\n",
    "data_y.head()\n",
    "#All other dates\n",
    "data_x = data.drop(columns=[\"dec\"])\n",
    "data_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization dates\n",
    "dates_x = pd.get_dummies(dates_x)\n",
    "\n",
    "#Scale values out of range\n",
    "escalador = StandardScaler()\n",
    "dates_x = escalador.fit_transform(dates_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (2800, 217), X Test: (701, 217), y_train (2800,), y_test (701,)\n"
     ]
    }
   ],
   "source": [
    "#Shape data in train and test\n",
    "dates_x.shape[0]\n",
    "\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(dates_x,dates_y,test_size=0.2, random_state=2)\n",
    "\n",
    "print(\"X Train: {}, X Test: {}, y_train {}, y_test {}\".format(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape))\n",
    "\n",
    "n_inputs = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Transform to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the array of np or pnds to tensors\n",
    "t_X_train = torch.from_numpy(X_train).float().to(\"cuda\")\n",
    "t_X_test = torch.from_numpy(X_test).float().to(\"cuda\")\n",
    "t_Y_train = torch.from_numpy(Y_train.values).float().to(\"cuda\")\n",
    "t_Y_test = torch.from_numpy(Y_test.values).float().to(\"cuda\")\n",
    "t_Y_train = t_Y_train[:,None]\n",
    "t_Y_test = t_Y_test[:,None]\n",
    "\n",
    "#define tensor test\n",
    "test = TensorDataset(t_X_test,t_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Create a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Red(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Red, self).__init__()\n",
    "        self.linear1 = nn.Linear(n_inputs, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)  \n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.1)  \n",
    "        self.linear3 = nn.Linear(64, 32)\n",
    "        self.linear4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.linear1(inputs))\n",
    "        x = self.dropout1(x) \n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)  \n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Create a train function and test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function\n",
    "def train(model, optimizer, loss_fn, t_X_train, t_Y_train, epochs, status_print):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(t_X_train)\n",
    "        loss = loss_fn(input=Y_pred, target=t_Y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % status_print == 0:\n",
    "            print(f\"\\nEpoch {epoch} \\t Loss: {round(loss.item(), 4)}\")\n",
    "\n",
    "# Test function\n",
    "def test(model, t_X_test, t_Y_test, status_print):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred = model(t_X_test)\n",
    "        Y_pred_class = Y_pred.round()\n",
    "        correct = (Y_pred_class == t_Y_test).sum()\n",
    "        accuracy = 100 * correct / float(len(t_Y_test))\n",
    "\n",
    "        if status_print == 0:\n",
    "            print(\"Accuracy: {}\".format(accuracy.item()))\n",
    "        return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Parameters of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 2000\n",
    "status_print = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3.4 Inicialice model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Red(n_inputs=n_inputs)\n",
    "model.to(\"cuda\")\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Make a prediction with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo\n",
      "\n",
      "Epoch 100 \t Loss: 0.0033\n",
      "\n",
      "Epoch 200 \t Loss: 0.0014\n",
      "\n",
      "Epoch 300 \t Loss: 0.0052\n",
      "\n",
      "Epoch 400 \t Loss: 0.0027\n",
      "\n",
      "Epoch 500 \t Loss: 0.007\n",
      "\n",
      "Epoch 600 \t Loss: 0.0065\n",
      "\n",
      "Epoch 700 \t Loss: 0.0009\n",
      "\n",
      "Epoch 800 \t Loss: 0.0025\n",
      "\n",
      "Epoch 900 \t Loss: 0.0009\n",
      "\n",
      "Epoch 1000 \t Loss: 0.0012\n",
      "\n",
      "Epoch 1100 \t Loss: 0.0015\n",
      "\n",
      "Epoch 1200 \t Loss: 0.0031\n",
      "\n",
      "Epoch 1300 \t Loss: 0.002\n",
      "\n",
      "Epoch 1400 \t Loss: 0.0019\n",
      "\n",
      "Epoch 1500 \t Loss: 0.0013\n",
      "\n",
      "Epoch 1600 \t Loss: 0.0019\n",
      "\n",
      "Epoch 1700 \t Loss: 0.0012\n",
      "\n",
      "Epoch 1800 \t Loss: 0.0028\n",
      "\n",
      "Epoch 1900 \t Loss: 0.0058\n",
      "\n",
      "Epoch 2000 \t Loss: 0.0046\n",
      "Evaluando el modelo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(83.4522, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test model\n",
    "print(\"Entrenando el modelo\")\n",
    "train(model, optimizer, loss_fn, t_X_train, t_Y_train, epochs, status_print)\n",
    "print(\"Evaluando el modelo\")\n",
    "test(model, t_X_test, t_Y_test, status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
